{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4XFWA1aVvWJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.stats import pearsonr\n",
        "import random\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import glob\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPNTbdLJVwCd",
        "outputId": "a4e732ee-da93-4f5c-f706-7f4cf52dbd89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('images/images')"
      ],
      "metadata": {
        "id": "OvH9TJO1VyUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_df = pd.read_csv('artists.csv')"
      ],
      "metadata": {
        "id": "a0fppxJLV0pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height, img_width = 224, 224\n",
        "artists_names= sorted(artist_df['name'].str.replace(' ', '_').tolist())\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir, \n",
        "    validation_split=0.2, \n",
        "    seed=123,\n",
        "    subset='training',\n",
        "    image_size=(img_height, img_width), \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir, \n",
        "    validation_split=0.2, \n",
        "    seed=123,\n",
        "    subset='validation', \n",
        "    image_size=(img_height, img_width), \n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VImPSUtV2hZ",
        "outputId": "c4ea21de-02d2-4f47-b9e5-6d55ecd67fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8461 files belonging to 50 classes.\n",
            "Using 6769 files for training.\n",
            "Found 8461 files belonging to 50 classes.\n",
            "Using 1692 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 50\n",
        "input_shape = (batch_size, img_height, img_width, 3)\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255,input_shape=(img_height, img_width, 3)))\n",
        "model.add(tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"))\n",
        "model.add(tf.keras.layers.experimental.preprocessing.RandomFlip(\"vertical\"))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.build(input_shape)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ww2SUDgV4if",
        "outputId": "f4135924-3031-42c7-85f2-e54692c409f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_flip_1 (RandomFlip)  (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 256)       147712    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 173056)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               88605184  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                25650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,060,594\n",
            "Trainable params: 89,060,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "num_epochs = 50\n",
        "start_time = time.time()\n",
        "model_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=num_epochs,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "loss, accuracy = model.evaluate(val_ds)\n",
        "print(f'Validation accuracy: {accuracy}')\n",
        "print(f'Validation loss: {loss:.4f}')\n",
        "training_time_minutes = round(training_time / 60, 2)\n",
        "print(f\"Training time: {training_time_minutes} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz6eWgYoWBXU",
        "outputId": "ac119133-8a0c-4de3-a45e-15e1bec6d6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "212/212 [==============================] - 304s 1s/step - loss: 5.7894 - accuracy: 0.1077 - val_loss: 4.1040 - val_accuracy: 0.1708\n",
            "Epoch 2/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.8833 - accuracy: 0.1474 - val_loss: 3.5909 - val_accuracy: 0.1371\n",
            "Epoch 3/50\n",
            "212/212 [==============================] - 14s 63ms/step - loss: 3.5511 - accuracy: 0.1566 - val_loss: 3.4059 - val_accuracy: 0.1814\n",
            "Epoch 4/50\n",
            "212/212 [==============================] - 14s 63ms/step - loss: 3.4261 - accuracy: 0.1629 - val_loss: 3.2994 - val_accuracy: 0.1986\n",
            "Epoch 5/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 3.3871 - accuracy: 0.1656 - val_loss: 3.2687 - val_accuracy: 0.1767\n",
            "Epoch 6/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 3.3408 - accuracy: 0.1711 - val_loss: 3.2295 - val_accuracy: 0.2039\n",
            "Epoch 7/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.2841 - accuracy: 0.1813 - val_loss: 3.1961 - val_accuracy: 0.2033\n",
            "Epoch 8/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.2715 - accuracy: 0.1847 - val_loss: 3.2073 - val_accuracy: 0.2051\n",
            "Epoch 9/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 3.2748 - accuracy: 0.1997 - val_loss: 3.1347 - val_accuracy: 0.2287\n",
            "Epoch 10/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.2469 - accuracy: 0.2133 - val_loss: 3.1617 - val_accuracy: 0.2358\n",
            "Epoch 11/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.2152 - accuracy: 0.2170 - val_loss: 3.0472 - val_accuracy: 0.2535\n",
            "Epoch 12/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.1724 - accuracy: 0.2219 - val_loss: 3.0926 - val_accuracy: 0.2494\n",
            "Epoch 13/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.1591 - accuracy: 0.2277 - val_loss: 3.0650 - val_accuracy: 0.2719\n",
            "Epoch 14/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 3.1170 - accuracy: 0.2353 - val_loss: 2.9796 - val_accuracy: 0.2837\n",
            "Epoch 15/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.0884 - accuracy: 0.2408 - val_loss: 3.0205 - val_accuracy: 0.2819\n",
            "Epoch 16/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.0884 - accuracy: 0.2417 - val_loss: 2.9427 - val_accuracy: 0.2849\n",
            "Epoch 17/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 3.0770 - accuracy: 0.2463 - val_loss: 2.9941 - val_accuracy: 0.2648\n",
            "Epoch 18/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.0321 - accuracy: 0.2495 - val_loss: 2.9230 - val_accuracy: 0.2937\n",
            "Epoch 19/50\n",
            "212/212 [==============================] - 13s 61ms/step - loss: 3.0222 - accuracy: 0.2593 - val_loss: 2.9455 - val_accuracy: 0.2896\n",
            "Epoch 20/50\n",
            "212/212 [==============================] - 13s 61ms/step - loss: 3.0062 - accuracy: 0.2621 - val_loss: 2.8820 - val_accuracy: 0.2996\n",
            "Epoch 21/50\n",
            "212/212 [==============================] - 14s 63ms/step - loss: 2.9849 - accuracy: 0.2658 - val_loss: 2.9186 - val_accuracy: 0.2996\n",
            "Epoch 22/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 3.0033 - accuracy: 0.2684 - val_loss: 2.8870 - val_accuracy: 0.2961\n",
            "Epoch 23/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9917 - accuracy: 0.2712 - val_loss: 2.8805 - val_accuracy: 0.3121\n",
            "Epoch 24/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9697 - accuracy: 0.2839 - val_loss: 2.8323 - val_accuracy: 0.3097\n",
            "Epoch 25/50\n",
            "212/212 [==============================] - 14s 63ms/step - loss: 2.9386 - accuracy: 0.2807 - val_loss: 2.9438 - val_accuracy: 0.2991\n",
            "Epoch 26/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9530 - accuracy: 0.2872 - val_loss: 3.0461 - val_accuracy: 0.2547\n",
            "Epoch 27/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9520 - accuracy: 0.2918 - val_loss: 2.8661 - val_accuracy: 0.3091\n",
            "Epoch 28/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9241 - accuracy: 0.2956 - val_loss: 2.8279 - val_accuracy: 0.3339\n",
            "Epoch 29/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9382 - accuracy: 0.2944 - val_loss: 2.9320 - val_accuracy: 0.3056\n",
            "Epoch 30/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9448 - accuracy: 0.3008 - val_loss: 2.8519 - val_accuracy: 0.3180\n",
            "Epoch 31/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9097 - accuracy: 0.2958 - val_loss: 2.8289 - val_accuracy: 0.3292\n",
            "Epoch 32/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9227 - accuracy: 0.2987 - val_loss: 2.8334 - val_accuracy: 0.3274\n",
            "Epoch 33/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.9044 - accuracy: 0.3080 - val_loss: 2.8682 - val_accuracy: 0.3274\n",
            "Epoch 34/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8958 - accuracy: 0.3119 - val_loss: 2.8111 - val_accuracy: 0.3392\n",
            "Epoch 35/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8916 - accuracy: 0.3130 - val_loss: 2.8594 - val_accuracy: 0.3274\n",
            "Epoch 36/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8719 - accuracy: 0.3232 - val_loss: 2.8155 - val_accuracy: 0.3493\n",
            "Epoch 37/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 2.8948 - accuracy: 0.3113 - val_loss: 2.8076 - val_accuracy: 0.3398\n",
            "Epoch 38/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.8777 - accuracy: 0.3185 - val_loss: 2.8564 - val_accuracy: 0.3392\n",
            "Epoch 39/50\n",
            "212/212 [==============================] - 14s 64ms/step - loss: 2.8640 - accuracy: 0.3249 - val_loss: 2.8163 - val_accuracy: 0.3422\n",
            "Epoch 40/50\n",
            "212/212 [==============================] - 14s 65ms/step - loss: 2.8708 - accuracy: 0.3283 - val_loss: 2.8242 - val_accuracy: 0.3387\n",
            "Epoch 41/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8709 - accuracy: 0.3286 - val_loss: 2.8686 - val_accuracy: 0.3511\n",
            "Epoch 42/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8564 - accuracy: 0.3336 - val_loss: 2.8546 - val_accuracy: 0.3410\n",
            "Epoch 43/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8461 - accuracy: 0.3379 - val_loss: 2.7857 - val_accuracy: 0.3717\n",
            "Epoch 44/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8450 - accuracy: 0.3328 - val_loss: 2.8493 - val_accuracy: 0.3446\n",
            "Epoch 45/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8281 - accuracy: 0.3383 - val_loss: 2.8392 - val_accuracy: 0.3576\n",
            "Epoch 46/50\n",
            "212/212 [==============================] - 13s 62ms/step - loss: 2.8360 - accuracy: 0.3432 - val_loss: 2.8105 - val_accuracy: 0.3717\n",
            "Epoch 47/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8127 - accuracy: 0.3498 - val_loss: 2.7849 - val_accuracy: 0.3735\n",
            "Epoch 48/50\n",
            "212/212 [==============================] - 14s 63ms/step - loss: 2.8032 - accuracy: 0.3488 - val_loss: 2.7621 - val_accuracy: 0.3818\n",
            "Epoch 49/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8337 - accuracy: 0.3450 - val_loss: 2.7660 - val_accuracy: 0.3717\n",
            "Epoch 50/50\n",
            "212/212 [==============================] - 14s 62ms/step - loss: 2.8167 - accuracy: 0.3534 - val_loss: 2.8168 - val_accuracy: 0.3830\n",
            "53/53 [==============================] - 3s 43ms/step - loss: 2.8168 - accuracy: 0.3830\n",
            "Validation accuracy: 0.38297873735427856\n",
            "Validation loss: 2.8168\n",
            "Training time: 16.2 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "ax1.plot(model_history.history['accuracy'], linestyle='-', linewidth=2, label='Train Accuracy')\n",
        "ax1.plot(model_history.history['val_accuracy'], linestyle='--', linewidth=2, label='Validation Accuracy')\n",
        "ax1.set_title('Model Accuracy', fontweight='bold')\n",
        "ax1.set_ylabel('Accuracy', fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontweight='bold')\n",
        "ax1.legend(loc='upper left')\n",
        "ax2.plot(model_history.history['loss'], linestyle='-', linewidth=2, label='Train Loss')\n",
        "ax2.plot(model_history.history['val_loss'], linestyle='--', linewidth=2, label='Validation Loss')\n",
        "ax2.set_title('Model Loss', fontweight='bold')\n",
        "ax2.set_ylabel('Loss', fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontweight='bold')\n",
        "ax2.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TUqVfiQvaDHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "val_class_labels = [val_ds.class_names[label] for label in val_labels]\n",
        "y_pred = model.predict(val_ds) \n",
        "y_pred_classes = np.argmax(y_pred, axis=1) \n",
        "y_pred_classes = y_pred_classes.tolist()\n",
        "\n",
        "artists_names = sorted(artist_df['name'].str.replace(' ', '_').tolist())\n",
        "n_artists = len(artists_names)\n",
        "artist_dict = {}\n",
        "for i in range(n_artists):\n",
        "    artist_dict[i] = artists_names[i]\n",
        "\n",
        "artist_names_pred = [artist_dict[label] for label in y_pred_classes]\n",
        "artist_names_true = val_class_labels\n",
        "\n",
        "print(classification_report(artist_names_true, artist_names_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "IBJIwHJwaFql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(artist_names_true, artist_names_pred, average='macro', zero_division=0)\n",
        "print(\"Precision of the model\", precision)\n",
        "recall = recall_score(artist_names_true, artist_names_pred, average='macro', zero_division=0)\n",
        "print(\"Recall of the model\", recall)\n",
        "f1 = f1_score(artist_names_true, artist_names_pred, average='macro', zero_division=0)\n",
        "print(\"F1-score of the model\", f1)"
      ],
      "metadata": {
        "id": "Mic5ZY6YaIC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(artist_names_true, artist_names_pred, zero_division=0)\n",
        "\n",
        "f1_scores = {}\n",
        "for line in report.split('\\n')[2:-5]:\n",
        "    line = line.split()\n",
        "    if len(line) == 0:\n",
        "        continue\n",
        "    class_name = line[0]\n",
        "    f1_score = float(line[-1])\n",
        "    f1_scores[class_name] = f1_score\n",
        "\n",
        "top_classes = sorted(f1_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"Top 5 classes by f1-score:\")\n",
        "for class_name, f1_score in top_classes:\n",
        "    print(class_name)"
      ],
      "metadata": {
        "id": "nXFLeWtyaKl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}